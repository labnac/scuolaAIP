{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/labnac/scuolaAIP/blob/main/2_Perceptron_numpy_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bf-f7PmUpfXp"
      },
      "source": [
        "**implementation and training of a Perceptron Example using numpy**\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot datapoints"
      ],
      "metadata": {
        "id": "nCBHj6K95K_P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_data(a,b):\n",
        "  #Plotting\n",
        "  fig = plt.figure(figsize=(6,4))\n",
        "  plt.plot(a[:, 0][b == 0], a[:, 1][b == 0], 'r^')\n",
        "  plt.plot(a[:, 0][b == 1], a[:, 1][b == 1], 'bs')\n",
        "  plt.xlabel(\"feature 1\")\n",
        "  plt.ylabel(\"feature 2\")\n",
        "  plt.title('Random Classification Data with 2 classes')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "rQIp72Ddqyi8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate data using a dataset of sklearn"
      ],
      "metadata": {
        "id": "sfBQ8TbO5D8A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "X, t = datasets.make_blobs(n_samples=150,n_features=2,\n",
        "                           centers=2,cluster_std=1.5,\n",
        "                           random_state=2)\n",
        "\n",
        "plot_data(X,t)"
      ],
      "metadata": {
        "id": "mG0WdvDXq_Vj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creation of class Perceptron**"
      ],
      "metadata": {
        "id": "dBQDlex75-1O"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0G5ht2X3pgfy"
      },
      "source": [
        "class Perceptron(object):\n",
        "  def __init__(self, X, y, lr, epochs):\n",
        "    # X -> Input data\n",
        "    # y -> labels/target\n",
        "    # lr -> learning rate\n",
        "    # epochs --> Number of iterations\n",
        "\n",
        "    # m -> number of training examples\n",
        "    # n -> number of features\n",
        "    self.m, self.n = np.shape(X)\n",
        "\n",
        "    self.epochs = epochs\n",
        "    self.lr=lr\n",
        "\n",
        "    # Initializing parameters(weights) to zeros\n",
        "    self.weights = np.zeros((self.n+1,1))\n",
        "\n",
        "    #Adding bias to the input\n",
        "    self.inputANN = self.add_bias(X)\n",
        "\n",
        "  # END of constructor\n",
        "\n",
        "  #Add bias to the input\n",
        "  def add_bias(self, x):\n",
        "    # input -> input for the ANN\n",
        "    if x.ndim > 1:\n",
        "      inp = np.insert(x,self.n,1,axis=1)\n",
        "    else:\n",
        "      inp = np.insert(x,2,1)\n",
        "    return inp\n",
        "  # END of function\n",
        "\n",
        "  #Calculates the activation of the neuron\n",
        "  def activation(self,x):\n",
        "    net_input = np.dot(x,self.weights)\n",
        "    output = self.step_func(net_input)\n",
        "    return output\n",
        "\n",
        "  #defining the activation function\n",
        "  def step_func(self, x):\n",
        "    if (x > 0):\n",
        "      return 1\n",
        "    else:\n",
        "      return 0\n",
        "  #END of function\n",
        "\n",
        "  # Training the ANN\n",
        "  def train(self):\n",
        "\n",
        "    for epoch in range(self.epochs):\n",
        "\n",
        "        # variable to store misclassified example\n",
        "        n_miss = 0\n",
        "\n",
        "        # looping for every example.\n",
        "        for idx, i in enumerate(self.inputANN):\n",
        "\n",
        "            # reshape the array\n",
        "            i = i.reshape(1,self.n+1)\n",
        "            # Calculating prediction - outpurt of the ANN\n",
        "            output = self.activation(i)\n",
        "\n",
        "            if (t[idx] - output) != 0:\n",
        "                # Updating if the example is misclassified\n",
        "                n_miss += 1\n",
        "                #delta rule\n",
        "                self.weights += self.lr*((t[idx] - output)*i.T)\n",
        "            # end of if\n",
        "\n",
        "        print(epoch, n_miss)  #end of epoch\n",
        "\n",
        "    return self.weights\n",
        "    #END of function\n",
        "\n",
        "  #Activate the ANN\n",
        "  def predict(self, x):\n",
        "    x = self.add_bias(x)\n",
        "    output = self.activation(x)\n",
        "    return output\n",
        "\n",
        "# END of CLASS"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create the instance of the class Perceptron\n",
        "\n",
        "learning_rate = 0.5\n",
        "epochs = 10\n",
        "\n",
        "perc = Perceptron(X, t, learning_rate, epochs)\n",
        "\n",
        "perc.train()\n",
        "\n",
        "t_pred = np.empty(0)\n",
        "for x in X:\n",
        "  val = perc.predict(x)\n",
        "  t_pred = np.append(t_pred, val)\n",
        "\n",
        "\n",
        "plot_data(X, t_pred)"
      ],
      "metadata": {
        "id": "KdPPIxhg-rPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  #def sigmoid(self, x):\n",
        "  #  return 1/(1+np.exp(-x))"
      ],
      "metadata": {
        "id": "8n1oesrk7t1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_decision_regions(perc, X, t, points=200)"
      ],
      "metadata": {
        "id": "cU6qYmEq8upQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.colors import ListedColormap\n",
        "\n",
        "def plot_decision_regions(network, X, y, points=200):\n",
        "    markers = ('o', '^')\n",
        "    colors = ('red', 'blue')\n",
        "    cmap = ListedColormap(colors)\n",
        "\n",
        "    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "\n",
        "\n",
        "    resolution = max(x1_max - x1_min, x2_max - x2_min) / float(points)\n",
        "\n",
        "    xx1, xx2 = np.meshgrid(np.arange(x1_min,\n",
        "                                           x1_max,\n",
        "                                           resolution),\n",
        "                              np.arange(x2_min, x2_max, resolution))\n",
        "    input = np.array([xx1.ravel(), xx2.ravel()]).T\n",
        "    Z = np.empty(0)\n",
        "\n",
        "  #### In this loop, it applies .predict() #######\n",
        "    for i in range(input.shape[0]):\n",
        "        val = network.predict(np.array(input[i]))\n",
        "        #if val < 0.5:\n",
        "        #    val = 0\n",
        "        #if val >= 0.5:\n",
        "        #    val = 1\n",
        "        Z = np.append(Z, val)\n",
        "\n",
        "    Z = Z.reshape(xx1.shape)\n",
        "\n",
        "    plt.pcolormesh(xx1, xx2, Z, cmap=cmap)\n",
        "    plt.xlim(xx1.min(), xx1.max())\n",
        "    plt.ylim(xx2.min(), xx2.max())\n",
        "    # plot all samples\n",
        "\n",
        "    classes = [\"False\", \"True\"]\n",
        "\n",
        "    for idx, cl in enumerate(np.unique(y)):\n",
        "        plt.scatter(x=X[y == cl, 0],\n",
        "                    y=X[y == cl, 1],\n",
        "                    alpha=1.0,\n",
        "                    c=colors[idx],\n",
        "                    edgecolors='black',\n",
        "                    marker=markers[idx],\n",
        "                    s=80,\n",
        "                    label=classes[idx])\n",
        "\n",
        "    plt.xlabel('x-axis')\n",
        "    plt.ylabel('y-axis')\n",
        "    plt.legend(loc='upper left')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "gwi0S5f78nCq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}