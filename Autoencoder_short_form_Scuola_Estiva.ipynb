{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Import dei moduli"
      ],
      "metadata": {
        "id": "HTsMQHcgs8Ca"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KGBFSYIeoolH"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import keras\n",
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n",
        "from keras import regularizers, optimizers, callbacks\n",
        "from keras.callbacks import TensorBoard\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definizione dell'autoencoder"
      ],
      "metadata": {
        "id": "7-KDuNl5s_Ii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.simplefilter(action='ignore', category=DeprecationWarning)\n",
        "\n",
        "\n",
        "def create_autoencoder(input_dim, l_rate, name='autoencoder'):\n",
        "    # Create model\n",
        "    autoencoder = Sequential(name=name)\n",
        "\n",
        "    # Encoder\n",
        "    autoencoder.add(Dense(5, input_dim=input_dim, activation='sigmoid'))\n",
        "\n",
        "    # Internal layer\n",
        "    autoencoder.add(Dense(3, activation='linear'))\n",
        "\n",
        "    # Decoder\n",
        "    autoencoder.add(Dense(5, activation='sigmoid'))\n",
        "\n",
        "    # Output layer\n",
        "    autoencoder.add(Dense(input_dim, activation='linear'))\n",
        "\n",
        "    # Compile model\n",
        "    autoencoder.compile(loss='mean_squared_error',\n",
        "                        optimizer=tf.keras.optimizers.Adam(learning_rate = l_rate))\n",
        "\n",
        "    return autoencoder\n",
        "\n",
        "def get_output(data):\n",
        "    new_model = tf.keras.Model(inputs=autoencoder_model.input, outputs=autoencoder_model.output, verbose = 0)\n",
        "    output_layer = new_model.predict(data)\n",
        "    return output_layer"
      ],
      "metadata": {
        "id": "zDN6ANjLowDG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Caricamento del Dataset"
      ],
      "metadata": {
        "id": "e4HKhU_QiDLU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Dataset = np.loadtxt(\"Heterogeneous_1000_1.txt\", skiprows=1, delimiter=\",\")"
      ],
      "metadata": {
        "id": "pt2b9G00qh4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Addestramento dell'autoencoder"
      ],
      "metadata": {
        "id": "AyG3skReiH_i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_features = Dataset.shape[1]\n",
        "\n",
        "l_rate = 5e-3\n",
        "\n",
        "autoencoder_model = create_autoencoder(n_features, l_rate)\n",
        "\n",
        "autoencoder_model.summary()\n",
        "\n",
        "history_dict = {}\n",
        "\n",
        "# TensorBoard Callback\n",
        "cb = TensorBoard()\n",
        "\n",
        "history_callback = autoencoder_model.fit(Dataset, Dataset,\n",
        "                              batch_size=4,\n",
        "                              epochs=50,\n",
        "                              verbose=1,\n",
        "                              callbacks=[cb])\n",
        "\n",
        "#mse_autoencoder = history_callback.history['mean_squared_error'][-1]\n",
        "\n",
        "score = autoencoder_model.evaluate(Dataset, Dataset, verbose=0)\n",
        "\n",
        "print(history_callback)\n",
        "history_dict[autoencoder_model.name] = [history_callback, autoencoder_model]"
      ],
      "metadata": {
        "id": "FnoaUpjNsepB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d9b0c93-62fc-46c9-df11-7510b87027cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"autoencoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 5)                 140       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 3)                 18        \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 5)                 20        \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 27)                162       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 340\n",
            "Trainable params: 340\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "250/250 [==============================] - 3s 4ms/step - loss: 2.6182\n",
            "Epoch 2/50\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 1.0432\n",
            "Epoch 3/50\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 1.0412\n",
            "Epoch 4/50\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 1.0203\n",
            "Epoch 5/50\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 1.0120\n",
            "Epoch 6/50\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.9929\n",
            "Epoch 7/50\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.9872\n",
            "Epoch 8/50\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.9791\n",
            "Epoch 9/50\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.9598\n",
            "Epoch 10/50\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.9520\n",
            "Epoch 11/50\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.9328\n",
            "Epoch 12/50\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.9104\n",
            "Epoch 13/50\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.8871\n",
            "Epoch 14/50\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.8437\n",
            "Epoch 15/50\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.8113\n",
            "Epoch 16/50\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.7948\n",
            "Epoch 17/50\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.7861\n",
            "Epoch 18/50\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.7782\n",
            "Epoch 19/50\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.7742\n",
            "Epoch 20/50\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.7742\n",
            "Epoch 21/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.7680\n",
            "Epoch 22/50\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.7625\n",
            "Epoch 23/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.7628\n",
            "Epoch 24/50\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.7600\n",
            "Epoch 25/50\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.7597\n",
            "Epoch 26/50\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.7581\n",
            "Epoch 27/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.7572\n",
            "Epoch 28/50\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.7570\n",
            "Epoch 29/50\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.7563\n",
            "Epoch 30/50\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.7517\n",
            "Epoch 31/50\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.7334\n",
            "Epoch 32/50\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6967\n",
            "Epoch 33/50\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6698\n",
            "Epoch 34/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.6589\n",
            "Epoch 35/50\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6495\n",
            "Epoch 36/50\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6427\n",
            "Epoch 37/50\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6388\n",
            "Epoch 38/50\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6347\n",
            "Epoch 39/50\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6312\n",
            "Epoch 40/50\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6300\n",
            "Epoch 41/50\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6292\n",
            "Epoch 42/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.6282\n",
            "Epoch 43/50\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6270\n",
            "Epoch 44/50\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6264\n",
            "Epoch 45/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.6245\n",
            "Epoch 46/50\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6252\n",
            "Epoch 47/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.6261\n",
            "Epoch 48/50\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6239\n",
            "Epoch 49/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.6245\n",
            "Epoch 50/50\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6247\n",
            "<keras.callbacks.History object at 0x7bf30264e4d0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = history_dict[autoencoder_model.name][0].history['loss']\n",
        "plt.plot(loss, label= autoencoder_model.name + \" loss\")\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epochs')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "OZ9amAJVxXIn",
        "outputId": "a2a523f8-3ce2-4582-f99a-c0b1c3fd68e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'epochs')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Procedura di selezione degli item"
      ],
      "metadata": {
        "id": "isbIUHTriLur"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#creo un vettore che va da 0 al numero di variabili\n",
        "variables_range = range(0,n_features)\n",
        "\n",
        "#produco una copia del dataset da cui andrò ad annullare le variabili\n",
        "Dataset_to_drop = np.copy(Dataset)\n",
        "\n",
        "#creo due liste che conterranno le variabili e gli errori di ricostruzione per ogni step della procedura\n",
        "ann_var = []\n",
        "min_MSE = []\n",
        "#inizializzo il primo loop che scorre su tutte le variabili. Questi sono gli step della procedura.\n",
        "for variable in variables_range:\n",
        "\n",
        "    MSE_Scores = [] #inizializzo una lista che conterrà gli errori per ogni variabile annullata ad ogni SINGOLO step\n",
        "\n",
        "    for iteration in variables_range: # loop per iterare su tutte le variabili AD OGNI STEP\n",
        "\n",
        "        mult_vector = np.ones(Dataset_to_drop.shape[1]) #definisco un vettore di 1 con tanti elementi quante sono le mie variabili\n",
        "\n",
        "        #se nella specifica iterazione il valore è ancora diverso da 0 (cioè non è stato già annullato nelle iterazioni precedenti)\n",
        "        if np.any(Dataset_to_drop[:, iteration] != 0):\n",
        "\n",
        "          np.put(mult_vector, [iteration], [0]) #lo pongo pari a 0 nel vettore che ho creato per aiutarmi\n",
        "\n",
        "        #ora posso moltiplicare il vettore alla matrice. in questo modo tutta la colonna della variabile sarà 0\n",
        "          X_Ann_Var = Dataset_to_drop*mult_vector\n",
        "\n",
        "        #passo alla rete nete neurale il dataset con la variabile annullata e ottengo in output la ricostruzione della long-form\n",
        "          reconstructed_array = get_output(X_Ann_Var)\n",
        "\n",
        "        #arrotondo l'output per avere numeri interi\n",
        "          rounded_array = np.rint(reconstructed_array)\n",
        "\n",
        "        #calcolo l'errore di ricostruzione\n",
        "          MSE = mean_squared_error(Dataset, rounded_array, squared = False)\n",
        "\n",
        "         #conservo l'errore di ricostruzione nella lista  creata nel loop\n",
        "          MSE_Scores.append(MSE)\n",
        "\n",
        "        # se invece la variabile è già stata annullata, inserirò al posto dell'errore un numero fittizio molto alto, es. 999\n",
        "        else:\n",
        "          MSE_Scores.append(999)\n",
        "\n",
        "    #a questo punto trasformo la lista di MSE in un array numpy per recuperare\n",
        "    #l'indice del suo minimo e contestualmente il numero dell'item a questo associato\n",
        "    MSE_Scores = np.array(MSE_Scores)\n",
        "\n",
        "    #aggiungo 1 per recuperare il numero preciso del mio item annullato perchè gli indici partono da 0\n",
        "    ann_var.append (np.argmin(MSE_Scores) + 1)\n",
        "    #a questo punto annullo ufficialmente la variabile nel mio dataset e ripeto tutto per le variabili rimanenti\n",
        "    #passando all'iterazione successiva\n",
        "    Dataset_to_drop[:, (np.argmin(MSE_Scores))] = 0\n",
        "\n",
        "    #conservo il minimo MSE di questa iterazione per controllare come varia l'errore tra le diverse iterazioni\n",
        "    min_MSE.append(np.amin(MSE_Scores))\n"
      ],
      "metadata": {
        "id": "nN4P8flPMkSv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cbca38d-aaf2-4ba9-d8f5-41d4d5ce5ba3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 3ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 3ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 3ms/step\n",
            "32/32 [==============================] - 0s 3ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 3ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 3ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 3ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 3ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ann_var"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8-l4yXlwYLj",
        "outputId": "84ce5362-15dc-4b55-8f41-261880bff935"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[9,\n",
              " 27,\n",
              " 8,\n",
              " 16,\n",
              " 7,\n",
              " 17,\n",
              " 25,\n",
              " 26,\n",
              " 18,\n",
              " 14,\n",
              " 22,\n",
              " 11,\n",
              " 13,\n",
              " 5,\n",
              " 12,\n",
              " 23,\n",
              " 21,\n",
              " 3,\n",
              " 2,\n",
              " 4,\n",
              " 24,\n",
              " 19,\n",
              " 20,\n",
              " 15,\n",
              " 1,\n",
              " 6,\n",
              " 10]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    }
  ]
}