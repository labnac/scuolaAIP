{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/labnac/scuolaAIP/blob/main/4_autoencoder_nonlinear_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import dei moduli"
      ],
      "metadata": {
        "id": "f2a2Hgi1sloF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import keras\n",
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n",
        "from keras import regularizers, optimizers, callbacks\n",
        "from keras.callbacks import TensorBoard\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import math\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "metadata": {
        "id": "VYFTkvTYtNxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "INIZIALIZZAZIONE DEI PARAMETRI: Parametri del test"
      ],
      "metadata": {
        "id": "BtQRoXyWsu4c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rho = 0.8 #attendibilità del test"
      ],
      "metadata": {
        "id": "4Z5MbFWCst1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "INIZIALIZZAZIONE DEI PARAMETRI: Parametri del fattore"
      ],
      "metadata": {
        "id": "ZalEMUeUs3Lt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kappa = 0 #media fattoriale\n",
        "phi = 1 #varianza fattoriale"
      ],
      "metadata": {
        "id": "cSs0nEOes2zt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "INIZIALIZZAZIONE DEI PARAMETRI: Parametri della relazione tra item e fattore\n",
        "\n"
      ],
      "metadata": {
        "id": "3s6gCH4UtB4N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t = 0  #intercetta\n",
        "l = 0.8 #loading"
      ],
      "metadata": {
        "id": "IIpwQgh2tBaL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "INIZIALIZZAZIONE DEI PARAMETRI: Parametri del dataset"
      ],
      "metadata": {
        "id": "3pQ6tDXNtHDi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_size = 800 #numerosità campionaria\n",
        "n_lin = 4 #numero di item lineari\n",
        "n_sig = 4 #numero di item non lineari\n",
        "a = 3 #pendenza della sigmoide\n",
        "b = -1 #location della sigmoide"
      ],
      "metadata": {
        "id": "QuuD3iMGtHQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Funzione per la creazione del dataset"
      ],
      "metadata": {
        "id": "50qKB4KdtYHF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dataset(sample_size, rho, kappa, phi, t, l, a, b, n_lin, n_sig):\n",
        "    np.random.seed(seed=2022)\n",
        "    ### Simulazione dei punteggi fattoriali e dei dataset ###\n",
        "    NL_X = []\n",
        "    KSI = []\n",
        "    X = []\n",
        "    n_var = n_lin+n_sig\n",
        "    epsvar = ((1-rho)*phi)/rho #varianza dei residui\n",
        "\n",
        "    for i in range(sample_size):\n",
        "      ksi = kappa + math.sqrt(phi)*np.random.normal(0,1)\n",
        "      for s in range(n_sig):\n",
        "        nl_x = (((1/(1+np.exp(-a*(ksi-(b)))))*8) - 4) + (math.sqrt(epsvar)*np.random.normal(0, 1))#0.3*(((1/(1+np.exp(-a*(ksi-(b))))*2)-1)*10 +  0.8*ksi + (math.sqrt(epsvar)*np.random.normal(0, 1)))\n",
        "        NL_X.append(nl_x)\n",
        "        KSI.append(ksi)\n",
        "      for k in range(n_lin):\n",
        "          x = t + 0.8*ksi  + (math.sqrt(epsvar)*np.random.normal(0, 1))\n",
        "          X.append(x)\n",
        "          KSI.append(ksi)\n",
        "\n",
        "    #punteggi fattoriali#\n",
        "    KSI = np.array(KSI)\n",
        "    ksi_array = KSI.reshape(sample_size,n_var)\n",
        "\n",
        "    #dataset\n",
        "    NL_X = np.array(NL_X)\n",
        "    NL_X = NL_X.reshape(sample_size, n_sig)\n",
        "    X = np.array(X)\n",
        "    X = X.reshape(sample_size, n_lin)\n",
        "    dataset_array = np.append(NL_X, X, axis=1)\n",
        "    dataset_df = pd.DataFrame(dataset_array)\n",
        "\n",
        "    return ksi_array, dataset_df\n",
        "\n",
        "KSI, Dataset = dataset(sample_size, rho, kappa, phi, t, l, a, b, n_lin, n_sig)\n",
        "\n",
        "np.save('punteggi_fattoriali.npy',KSI)\n",
        "np.save('Dataset',Dataset)"
      ],
      "metadata": {
        "id": "jeyAZR4G_nqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "KSI = np.load('punteggi_fattoriali.npy')\n",
        "Dataset = np.load('Dataset.npy')"
      ],
      "metadata": {
        "id": "EJCqZuC7YvF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Funzione per la creazione del modello di autoencoder"
      ],
      "metadata": {
        "id": "vYAGHi1rtcjt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UcnNPKgMtIzp"
      },
      "outputs": [],
      "source": [
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.simplefilter(action='ignore', category=DeprecationWarning)\n",
        "\n",
        "\n",
        "def create_autoencoder(input_dim, l_rate, name='autoencoder'):\n",
        "    # Create model\n",
        "    autoencoder = Sequential(name=name)\n",
        "\n",
        "    # Encoder\n",
        "    autoencoder.add(Dense(5, input_dim=input_dim, activation='sigmoid'))\n",
        "\n",
        "    # Internal layer\n",
        "    autoencoder.add(Dense(1, activation='linear'))\n",
        "\n",
        "    # Decoder\n",
        "    autoencoder.add(Dense(5, activation='sigmoid'))\n",
        "\n",
        "    # Output layer\n",
        "    autoencoder.add(Dense(input_dim, activation='linear'))\n",
        "\n",
        "    # Compile model\n",
        "    autoencoder.compile(loss='mean_squared_error',\n",
        "                        optimizer=tf.keras.optimizers.Adam(learning_rate = l_rate))\n",
        "\n",
        "    return autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Generazione dei punteggi fattoriali e del dataset\n",
        "\n",
        "#KSI, Dataset = dataset(sample_size, rho, kappa, phi, t, l, a, b, n_lin, n_sig)\n",
        "\n",
        "#Creazione di un autoencoder basato sul modello precedente che analizzi il nostro dataset\n",
        "\n",
        "n_features = Dataset.shape[1] #definizione della dimensionalità dell'input sulla base del numero di colonne del dataset\n",
        "l_rate = 5e-3 #tasso di apprendimento\n",
        "\n",
        "autoencoder_model = create_autoencoder(n_features, l_rate)\n",
        "\n",
        "autoencoder_model.summary()\n",
        "\n",
        "history_dict = {}\n",
        "\n",
        "# TensorBoard Callback\n",
        "cb = TensorBoard()\n",
        "\n",
        "history_callback = autoencoder_model.fit(Dataset, Dataset,\n",
        "                              batch_size=4,\n",
        "                              epochs=100,\n",
        "                              verbose=1,\n",
        "                              callbacks=[cb])\n",
        "\n",
        "score = autoencoder_model.evaluate(Dataset, Dataset, verbose=0) #variabile che restituisce la media delle loss\n",
        "\n",
        "history_dict[autoencoder_model.name] = [history_callback, autoencoder_model]\n",
        "\n",
        "print(history_callback)\n",
        "print(score)\n"
      ],
      "metadata": {
        "id": "KT-_duQCW3nG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = history_dict[autoencoder_model.name][0].history['loss']\n",
        "plt.plot(loss, label=\"autoencoder_model\"+ \" loss\")\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epochs')"
      ],
      "metadata": {
        "id": "TdQw8DUiovcR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Funzioni per ottenere l'output dello strato interno e l'output finale dell'autoencoder"
      ],
      "metadata": {
        "id": "U7wyYk9ouJXF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_hidden(data):\n",
        "    new_model = tf.keras.Model(inputs=autoencoder_model.input, outputs=[autoencoder_model.layers[1].output, autoencoder_model.output])\n",
        "    hidden, output = new_model.predict(data)\n",
        "    return hidden\n",
        "\n",
        "def get_output(data):\n",
        "    new_model = tf.keras.Model(inputs=autoencoder_model.input, outputs=[autoencoder_model.layers[1].output, autoencoder_model.output])\n",
        "    hidden, output = new_model.predict(data)\n",
        "    return output"
      ],
      "metadata": {
        "id": "PxqtEYVOTcqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizzazione della relazione tra item e fattore"
      ],
      "metadata": {
        "id": "rZZsX1CtuWpk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_layer = get_hidden(Dataset)\n",
        "output_layer = get_output(Dataset)\n",
        "\n",
        "\n",
        "plt.scatter(KSI[:,0],Dataset[:,0])\n",
        "plt.scatter(-hidden_layer,output_layer[:,0])\n",
        "plt.xlabel(\"factor scores\")\n",
        "plt.ylabel(\"observed scores\")"
      ],
      "metadata": {
        "id": "mL4Km3o-TjMM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=1)\n",
        "pc_array = pca.fit(Dataset).transform(Dataset) #ARRAY\n",
        "proj_array = pca.inverse_transform(pc_array)\n",
        "\n",
        "plt.scatter(KSI[:,0],Dataset[:,0])\n",
        "plt.scatter(-pc_array,proj_array[:,0])\n",
        "plt.xlabel(\"factor scores\")\n",
        "plt.ylabel(\"observed scores\")"
      ],
      "metadata": {
        "id": "1Fnufg3qZ8jj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mse_autoencoder = mean_squared_error(KSI[:,0],-hidden_layer[:,0])\n",
        "print(mse_autoencoder)"
      ],
      "metadata": {
        "id": "tbOmaTxRalJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mse_pca = mean_squared_error(KSI[:,0],-pc_array[:,0])\n",
        "print(mse_pca)"
      ],
      "metadata": {
        "id": "jcWmnfRWa_Jj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "VISUALIZZAZIONE DELLA RICOSTRUZIONE DELLA RELAZIONE TRA ITEM E FATTORE DA PARTE DELL'AUTOENCODER"
      ],
      "metadata": {
        "id": "mqjYkmrrudA4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MSE DELLA RICOSTRUZIONE DELLA RELAZIONE TRA ITEM E FATTORE DA PARTE DELL'AUTOENCODER\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "9MlRtAi_uncI"
      }
    }
  ]
}